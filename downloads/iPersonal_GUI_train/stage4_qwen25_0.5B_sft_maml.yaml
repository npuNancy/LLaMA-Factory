### Train
# CUDA_VISIBLE_DEVICES=1 lmf train \
#   downloads/iPersonal_GUI_train/stage4_qwen25_0.5B_sft_maml.yaml \
#   > saves/logs/stage4/train_$(date +%Y%m%d_%H%M).txt
### model
model_name_or_path: /data4/yanxiaokai/Models/modelscope/hub/Qwen/Qwen2___5-0___5B-Instruct
# image_max_pixels: 262144
# video_max_pixels: 16384
trust_remote_code: true

### method
stage: sft
do_train: true # true用于训练, false用于评估
finetuning_type: lora
lora_rank: 8
lora_alpha: 16
lora_target: all

# deepspeed 分布式训练
# deepspeed: examples/deepspeed/ds_z3_config.json  # choices: [ds_z0_config.json, ds_z2_config.json, ds_z3_config.json]

# 要添加到 tokenizer 中的 special token。多个 special token 用逗号分隔。
# new_special_tokens: ["<Role>","</Role>","<Task>","</Task>","<Format>","</Format>","<Rules>","</Rules>","<choices>","</choices>"]
new_special_tokens: "<Role>,</Role>,<Task>,</Task>,<Format>,</Format>,<Rules>,</Rules>,<choices>,</choices>"

# freeze_vision_tower: true # choices: [true, false] Whether ot not to freeze vision tower in MLLM training. default=True
# freeze_multi_modal_projector: true # choices: [true, false] Whether or not to freeze the multi modal projector in MLLM training. default=True
# train_mm_proj_only: false # choices: [true, false ]Whether or not to train the multimodal projector for MLLM only. default=False

### dataset
dataset: 
  - iPersonal_GUI_stage4_user_1_train
  - iPersonal_GUI_stage4_user_2_train
  # - iPersonal_GUI_stage4_user_4_train
  # - iPersonal_GUI_stage4_user_6_train
  # - iPersonal_GUI_stage4_user_7_train
  # - iPersonal_GUI_stage4_user_8_train
  # - iPersonal_GUI_stage4_user_9_train
  # - iPersonal_GUI_stage4_user_11_train
  # - iPersonal_GUI_stage4_user_13_train
  # - iPersonal_GUI_stage4_user_14_train
  # - iPersonal_GUI_stage4_user_15_train
  # - iPersonal_GUI_stage4_user_16_train
  # - iPersonal_GUI_stage4_user_17_train
  # - iPersonal_GUI_stage4_user_20_train
  # - iPersonal_GUI_stage4_user_21_train
  # - iPersonal_GUI_stage4_user_22_train
  # - iPersonal_GUI_stage4_user_25_train
  # - iPersonal_GUI_stage4_user_28_train
  # - iPersonal_GUI_stage4_user_30_train
  # - iPersonal_GUI_stage4_user_33_train
  # - iPersonal_GUI_stage4_user_34_train
  # - iPersonal_GUI_stage4_user_35_train
  # - iPersonal_GUI_stage4_user_37_train
  # - iPersonal_GUI_stage4_user_42_train
  # - iPersonal_GUI_stage4_user_43_train
  # - iPersonal_GUI_stage4_user_44_train
  # - iPersonal_GUI_stage4_user_46_train
  # - iPersonal_GUI_stage4_user_47_train
  # - iPersonal_GUI_stage4_user_48_train
  # - iPersonal_GUI_stage4_user_50_train
  # - iPersonal_GUI_stage4_user_52_train
  # - iPersonal_GUI_stage4_user_53_train
  # - iPersonal_GUI_stage4_user_55_train
  # - iPersonal_GUI_stage4_user_56_train
  # - iPersonal_GUI_stage4_user_58_train
  # - iPersonal_GUI_stage4_user_61_train
  # - iPersonal_GUI_stage4_user_64_train
  # - iPersonal_GUI_stage4_user_67_train
  # - iPersonal_GUI_stage4_user_68_train
  # - iPersonal_GUI_stage4_user_69_train
  # - iPersonal_GUI_stage4_user_72_train
  # - iPersonal_GUI_stage4_user_73_train
  # - iPersonal_GUI_stage4_user_82_train
  # - iPersonal_GUI_stage4_user_84_train
  # - iPersonal_GUI_stage4_user_86_train
  # - iPersonal_GUI_stage4_user_87_train
  # - iPersonal_GUI_stage4_user_88_train
  # - iPersonal_GUI_stage4_user_90_train
  # - iPersonal_GUI_stage4_user_91_train
  # - iPersonal_GUI_stage4_user_93_train
  # - iPersonal_GUI_stage4_user_94_train
  # - iPersonal_GUI_stage4_user_96_train
  # - iPersonal_GUI_stage4_user_97_train
  # - iPersonal_GUI_stage4_user_99_train
  # - iPersonal_GUI_stage4_user_100_train
template: qwen
cutoff_len: 10000 # 输入的最大 token 数, 超过该长度会被截断。
max_samples: 1000000 # 每个数据集的最大样本数, 超过将被截断。
overwrite_cache: true # 是否覆盖缓存的训练和评估数据集。
preprocessing_num_workers: 16 # 预处理时使用的进程数量。

### output
# TODO: 开始训练前修改 output_dir
output_dir: saves/stage4/qwen25_0.5B/lora/test_0415
logging_steps: 10
save_steps: 10
plot_loss: true
overwrite_output_dir: true

### train
per_device_train_batch_size: 1
gradient_accumulation_steps: 2 # 梯度积累步数
learning_rate: 1.0e-4
num_train_epochs: 3
lr_scheduler_type: cosine
warmup_ratio: 0.1
bf16: true
ddp_timeout: 180000000

# resume_from_checkpoint: saves/qwen25vl_7B_stage3/lora/sft # 断点重训

### eval
## 可以使用 eval_dataset 指定验证集, 也可以使用 val_size 指定验证集比例
## eval_dataset 和 val_size 只能二选一
# val_size: 0.05 # 20000*0.05=1000
# eval_dataset: iPersonal_GUI_stage3_sft_100_test
# per_device_eval_batch_size: 1
# eval_strategy: steps
# eval_steps: 500
# predict_with_generate: true ## 会调用 metrics 计算相似度
# load_best_model_at_end: true # 是否在训练结束后加载最佳模型。
